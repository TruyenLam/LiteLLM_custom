# ðŸ”§ HÆ¯á»šNG DáºªN Cáº¬P NHáº¬T VÃ€ THÃŠM MODELS VÃ€O LITELLM

## ðŸš€ 3 CÃCH CHÃNH Äá»‚ QUáº¢N LÃ MODELS:

### 1. ðŸ“± CÃCH 1: Sá»¬ Dá»¤NG API TRá»°C TIáº¾P (RECOMMENDED)

#### ThÃªm Model Má»›i:
```bash
curl -X POST https://call.shareapiai.com/model/new \
  -H "Authorization: Bearer sk-hWv1u2fX3yG4zJ5kT6p7qR8sT9uV0wX1" \
  -H "Content-Type: application/json" \
  -d '{
    "model_name": "llama-3-1-70b",
    "litellm_params": {
      "model": "openai/meta-llama/llama-3.1-70b-instruct",
      "api_base": "https://api.aimlapi.com/v1",
      "api_key": "os.environ/AIMLAPI_KEY"
    },
    "model_info": {
      "description": "Llama 3.1 70B - Meta flagship model",
      "provider": "aimlapi",
      "max_tokens": 128000
    }
  }'
```

#### Xem Models Hiá»‡n Táº¡i:
```bash
curl -H "Authorization: Bearer sk-hWv1u2fX3yG4zJ5kT6p7qR8sT9uV0wX1" \
     https://call.shareapiai.com/v1/models
```

#### Xem Chi Tiáº¿t Models:
```bash
curl -H "Authorization: Bearer sk-hWv1u2fX3yG4zJ5kT6p7qR8sT9uV0wX1" \
     https://call.shareapiai.com/model/info
```

### 2. ðŸ CÃCH 2: Sá»¬ Dá»¤NG PYTHON SCRIPTS

#### A. Script Interactive (Recommended):
```bash
cd D:\Project_ShareAPIai\CODE\litellm
D:/Project_ShareAPIai/venv/Scripts/python.exe manage_models.py
```

**Features:**
- Menu interactive
- ThÃªm model tá»«ng cÃ¡i má»™t
- Batch thÃªm models phá»• biáº¿n
- Test models
- XÃ³a models (náº¿u há»— trá»£)

#### B. Script Quick Add:
```bash
D:/Project_ShareAPIai/venv/Scripts/python.exe quick_add_models.py
```

**Features:**
- ThÃªm 6 models phá»• biáº¿n má»™t lÃºc
- KhÃ´ng cáº§n input
- Cháº¡y nhanh

#### C. Script Fetch All AIMLAPI:
```bash
D:/Project_ShareAPIai/venv/Scripts/python.exe fetch_aimlapi_models.py
```

**Features:**
- Láº¥y táº¥t cáº£ 237 models tá»« AIMLAPI
- Táº¡o config file YAML
- Backup raw data

### 3. âš™ï¸ CÃCH 3: Cáº¬P NHáº¬T VIA AZURE CLI

#### ThÃªm Environment Variables:
```bash
az containerapp update --name litellm-app --resource-group rg-litellm \
  --set-env-vars NEW_MODEL_CONFIG="custom_value"
```

#### Restart Container:
```bash
az containerapp revision restart --name litellm-app --resource-group rg-litellm
```

## ðŸŽ¯ MODELS TEMPLATES THÆ¯á»œNG DÃ™NG:

### OpenAI Models:
```json
{
  "model_name": "gpt-4o",
  "litellm_params": {
    "model": "openai/gpt-4o",
    "api_base": "https://api.aimlapi.com/v1",
    "api_key": "os.environ/AIMLAPI_KEY"
  },
  "model_info": {
    "description": "GPT-4o via AIMLAPI",
    "provider": "aimlapi",
    "max_tokens": 128000,
    "supports_function_calling": true,
    "supports_vision": true
  }
}
```

### Anthropic Claude Models:
```json
{
  "model_name": "claude-3-opus",
  "litellm_params": {
    "model": "openai/claude-3-opus-20240229",
    "api_base": "https://api.aimlapi.com/v1",
    "api_key": "os.environ/AIMLAPI_KEY"
  },
  "model_info": {
    "description": "Claude 3 Opus via AIMLAPI",
    "provider": "aimlapi",
    "max_tokens": 200000,
    "supports_function_calling": true
  }
}
```

### Meta Llama Models:
```json
{
  "model_name": "llama-3-1-405b",
  "litellm_params": {
    "model": "openai/meta-llama/llama-3.1-405b-instruct",
    "api_base": "https://api.aimlapi.com/v1",
    "api_key": "os.environ/AIMLAPI_KEY"
  },
  "model_info": {
    "description": "Llama 3.1 405B - Meta's largest model",
    "provider": "aimlapi",
    "max_tokens": 128000,
    "supports_function_calling": true
  }
}
```

### Google Gemini Models:
```json
{
  "model_name": "gemini-1-5-pro",
  "litellm_params": {
    "model": "openai/gemini-1.5-pro-latest",
    "api_base": "https://api.aimlapi.com/v1",
    "api_key": "os.environ/AIMLAPI_KEY"
  },
  "model_info": {
    "description": "Gemini 1.5 Pro via AIMLAPI",
    "provider": "aimlapi",
    "max_tokens": 2097152,
    "supports_function_calling": true
  }
}
```

## ðŸ§ª TESTING MODELS:

### Test Model má»›i:
```bash
curl -X POST https://call.shareapiai.com/v1/chat/completions \
  -H "Authorization: Bearer sk-hWv1u2fX3yG4zJ5kT6p7qR8sT9uV0wX1" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "NEW_MODEL_NAME",
    "messages": [{"role": "user", "content": "Hello! Are you working?"}],
    "max_tokens": 50
  }'
```

### Test Function Calling:
```bash
curl -X POST https://call.shareapiai.com/v1/chat/completions \
  -H "Authorization: Bearer sk-hWv1u2fX3yG4zJ5kT6p7qR8sT9uV0wX1" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "MODEL_NAME",
    "messages": [{"role": "user", "content": "What is the weather in Hanoi?"}],
    "functions": [
      {
        "name": "get_weather",
        "description": "Get weather information",
        "parameters": {
          "type": "object",
          "properties": {
            "location": {"type": "string", "description": "City name"}
          }
        }
      }
    ]
  }'
```

## ðŸ”„ Cáº¬P NHáº¬T MODELS Äá»ŠNH Ká»²:

### 1. Cron Job Script:
```bash
# Táº¡o script tá»± Ä‘á»™ng cáº­p nháº­t
echo "#!/bin/bash" > update_models_daily.sh
echo "cd /path/to/project" >> update_models_daily.sh
echo "python fetch_aimlapi_models.py" >> update_models_daily.sh
echo "python quick_add_models.py" >> update_models_daily.sh
chmod +x update_models_daily.sh

# ThÃªm vÃ o crontab (cháº¡y má»—i ngÃ y lÃºc 2AM)
echo "0 2 * * * /path/to/update_models_daily.sh" | crontab -
```

### 2. GitHub Actions (CI/CD):
```yaml
name: Update LiteLLM Models
on:
  schedule:
    - cron: '0 2 * * *'  # Cháº¡y má»—i ngÃ y lÃºc 2AM
  workflow_dispatch:     # Cháº¡y thá»§ cÃ´ng

jobs:
  update-models:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'
      - name: Install dependencies
        run: pip install -r requirements.txt
      - name: Update models
        run: python quick_add_models.py
        env:
          AIMLAPI_KEY: ${{ secrets.AIMLAPI_KEY }}
```

## ðŸ“Š MONITORING VÃ€ ALERTING:

### Check Model Health:
```bash
# Script kiá»ƒm tra táº¥t cáº£ models
for model in $(curl -s -H "Authorization: Bearer $API_KEY" \
  https://call.shareapiai.com/v1/models | jq -r '.data[].id'); do
  echo "Testing $model..."
  curl -X POST https://call.shareapiai.com/v1/chat/completions \
    -H "Authorization: Bearer $API_KEY" \
    -H "Content-Type: application/json" \
    -d "{\"model\":\"$model\",\"messages\":[{\"role\":\"user\",\"content\":\"test\"}],\"max_tokens\":5}"
done
```

## ðŸš¨ TROUBLESHOOTING:

### Model khÃ´ng hoáº¡t Ä‘á»™ng:
1. Kiá»ƒm tra AIMLAPI_KEY cÃ³ Ä‘Ãºng khÃ´ng
2. Kiá»ƒm tra model name cÃ³ chÃ­nh xÃ¡c khÃ´ng
3. Kiá»ƒm tra API quota cÃ²n khÃ´ng
4. Restart container náº¿u cáº§n

### Model bá»‹ duplicate:
1. XÃ³a models cÅ© (náº¿u API há»— trá»£)
2. Hoáº·c restart container Ä‘á»ƒ reset

### Performance issues:
1. Kiá»ƒm tra rate limits
2. Monitor response times
3. Scale container resources náº¿u cáº§n

## ðŸŽ¯ BEST PRACTICES:

1. **Always test models** sau khi thÃªm
2. **Backup configurations** trÆ°á»›c khi thay Ä‘á»•i
3. **Monitor usage** Ä‘á»ƒ tá»‘i Æ°u cost
4. **Update regularly** Ä‘á»ƒ cÃ³ models má»›i
5. **Document changes** trong git commits

**ðŸ”¥ Vá»›i há»‡ thá»‘ng nÃ y, báº¡n cÃ³ thá»ƒ dá»… dÃ ng quáº£n lÃ½ hÃ ng trÄƒm AI models!**
